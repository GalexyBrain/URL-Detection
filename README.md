# Malicious URL Detection using Machine Learning and Deep Learning

This project provides a comprehensive framework for detecting malicious URLs using a variety of machine learning and deep learning models. It includes modules for feature extraction, model training, evaluation, and adversarial testing to assess model robustness.

## üöÄ Features

- **Diverse Model Support:** Implements a wide range of models, from classical ML (e.g., Random Forest, XGBoost) to advanced DL architectures (e.g., CharCNN, Transformers).
- **Rich Feature Extraction:** Extracts lexical and host-based features from URLs for tabular models.
- **End-to-End Workflow:** Scripts to handle the complete pipeline from data preparation to model evaluation.
- **Adversarial Robustness Testing:** Evaluates model performance against common adversarial attacks like FGSM and PGD.
- **Detailed Evaluation:** Generates classification reports, confusion matrices, ROC curves, and feature importance plots.
- **Organized Structure:** A clear and modular project structure for easy extension and experimentation.

## ‚öôÔ∏è Project Workflow

The project follows a sequential workflow managed by the `runThis.sh` script:

1.  **Merge Datasets:** Combines benign and malicious URL datasets into a single file.
2.  **Extract Features:** Processes the raw URLs to generate lexical and host-based features, saving them to a CSV file.
3.  **Train Models:** Trains and evaluates both Machine Learning and Deep Learning models on the processed data.
4.  **Attack Models:** Performs adversarial attacks on the trained models to test their security and robustness.

## üîß Setup and Installation

1.  **Clone the repository:**
    ```bash
    git clone <repository-url>
    cd MalURL
    ```

2.  **Create a Python virtual environment:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Install dependencies:**
    This project requires Python 3.8+. The required packages are listed in `requirements.txt`. Install them using pip:
    ```bash
    pip install -r requirements.txt
    ```

## ‚ñ∂Ô∏è Usage

The main execution script is `runThis.sh`. You can run the entire pipeline or specific stages.

**To run the full pipeline:**

```bash
bash runThis.sh all
```

**To run a specific step:**

```bash
# Merge the datasets
bash runThis.sh merge_datasets

# Extract features from the merged URLs
bash runThis.sh extract_features

# Train all Machine Learning models
bash runThis.sh train_ml_models

# Train all Deep Learning models
bash runThis.sh train_dl_models

# Perform adversarial attacks on all models
bash runThis.sh attack_models
```

## ü§ñ Models Implemented

### Machine Learning Models
- Logistic Regression
- Decision Tree
- Random Forest
- AdaBoost
- Gaussian Naive Bayes
- LightGBM
- XGBoost
- Calibrated LinearSVC

### Deep Learning Models
- **MLP:** Multi-Layer Perceptron on extracted features.
- **CharCNN:** Character-level Convolutional Neural Network.
- **CharTransformer:** Character-level Transformer model.
- **FTTransformer:** A Transformer-based model for tabular data.

## ‚öîÔ∏è Adversarial Attacks

The project uses the [Adversarial Robustness Toolbox (ART)](https://github.com/Trusted-AI/adversarial-robustness-toolbox) to evaluate model resilience against the following evasion attacks:

- **FGSM (Fast Gradient Sign Method)**
- **PGD (Projected Gradient Descent)**
- **NAT (Natural Transformation)**

Attack results, including classification reports and confusion matrices, are saved in the `results/{model_name}/adv_{attack_name}/` directory.

## üìä Results

All evaluation artifacts are stored in the `results/` directory, organized by model name. For each model, the following are generated:

- `metrics.json`: Key performance metrics (Accuracy, Precision, Recall, F1-Score).
- `classification_report.txt`: Detailed classification report from scikit-learn.
- `confusion_matrix.png`: A plot of the confusion matrix.
- `roc_curve.png`: A plot of the Receiver Operating Characteristic (ROC) curve.
- `feature_importance.png`: (For applicable ML models) A plot showing the most important features.

## üìÇ Project Structure

```
.
‚îú‚îÄ‚îÄ models/               # Saved trained models and tokenizers
‚îú‚îÄ‚îÄ results/              # Evaluation results and plots for each model
‚îú‚îÄ‚îÄ attackModels.py       # Script for running adversarial attacks
‚îú‚îÄ‚îÄ FeatureExtractor.py   # Extracts features from URLs
‚îú‚îÄ‚îÄ merge_datasets.py     # Merges benign and malicious URL lists
‚îú‚îÄ‚îÄ TrainAllModels_DL.py  # Trains and evaluates Deep Learning models
‚îú‚îÄ‚îÄ TrainAllModels_ML.py  # Trains and evaluates Machine Learning models
‚îú‚îÄ‚îÄ runThis.sh            # Main execution script
‚îî‚îÄ‚îÄ README.md             # This file
```

---
*This README was autogenerated by Gemini.*
